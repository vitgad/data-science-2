{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics\n",
    "In this tutorial we learn how to split data, transform data and apply regularization using logistic regression example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:45:07.527356Z",
     "start_time": "2022-01-22T09:45:07.514311Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:27.639406Z",
     "start_time": "2022-01-22T09:32:27.624400Z"
    }
   },
   "outputs": [],
   "source": [
    "# set width of Jupyter notebook\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "# set some visual properties of displaying pandas DataFrame\n",
    "pd.options.display.max_columns=200\n",
    "pd.options.display.max_rows=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the data if needed (and unpack it into the Data folder), we use the same dataset as in the python intro:** <a href=\"https://www2.karlin.mff.cuni.cz/~kozmikk/files/data_devsample.zip\" target=\"_blank\">credit risk data</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "- Data sample represents data used in financial institutions for development of credit risk scoring models.\n",
    "- This data sample was used in Kaggle competition arranged by Home Credit Group in 2018.\n",
    "- Data includes binary target variable `TARGET` and multiple regressors to be used in model.\n",
    "- Column `SK_ID_CURR` is used as unique identifier of credit application and columns `TIME` represents time of the application.\n",
    "- Model should predict solvency of applicants at the time of application for credit.\n",
    "\n",
    "Original [Kaggle competition](https://www.kaggle.com/competitions/home-credit-default-risk/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:30.284067Z",
     "start_time": "2022-01-22T09:32:29.180423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data - set index column, decimal point, separator\n",
    "data_file = Path(\"../Data/data_devsample.csv\")\n",
    "data = pd.read_csv(data_file, sep = ',', decimal = '.', index_col = 'SK_ID_CURR')\n",
    "\n",
    "# print time of data being loaded - use strftime\n",
    "print(f'Data loaded on:   {datetime.datetime.now().strftime(format=\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:30.473947Z",
     "start_time": "2022-01-22T09:32:30.459898Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:30.679894Z",
     "start_time": "2022-01-22T09:32:30.665895Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print some numbers about data sample size\n",
    "print(f'Number of rows:   {data.shape[0]:,}'.replace(',', ' '))\n",
    "print(f'Number of unique indexes:   {data.index.nunique():,}'.replace(',', ' '))\n",
    "print(f'Number of columns:   {data.shape[1]:,}'.replace(',', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:40.282299Z",
     "start_time": "2022-01-22T09:32:40.270256Z"
    }
   },
   "outputs": [],
   "source": [
    "# check values in column TARGET\n",
    "data.TARGET.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:49.945771Z",
     "start_time": "2022-01-22T09:32:49.928734Z"
    }
   },
   "outputs": [],
   "source": [
    "#name of the target column\n",
    "col_target = \"TARGET\"\n",
    "#name of the time column\n",
    "col_time = \"TIME\"\n",
    "\n",
    "#name of the month column\n",
    "col_month = \"MONTH\"\n",
    "# #name of the day column\n",
    "col_day = \"DAY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:56.831612Z",
     "start_time": "2022-01-22T09:32:56.132618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "description = data.describe(include='all').transpose()\n",
    "pd.options.display.max_rows = 1000\n",
    "display(description)\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:37:05.370916Z",
     "start_time": "2022-01-22T09:37:05.256888Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:32:51.326282Z",
     "start_time": "2022-01-22T09:32:51.252280Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define list of predictors\n",
    "cols = list(data.columns)\n",
    "\n",
    "# define list of numerical predictors\n",
    "cols_num = [col for col in cols if data[col].dtype != 'O']\n",
    "# define list of categorical predictors\n",
    "cols_cat = [col for col in cols if data[col].dtype == 'O']\n",
    "\n",
    "print('Numerical predictors:')\n",
    "print('---------------------')\n",
    "print(data[cols_num].dtypes)\n",
    "print()\n",
    "print('Categorical predictors:')\n",
    "print('-----------------------')\n",
    "print(data[cols_cat].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "- splitting data into training sample, validation sample, test sample, out of time sample and historical out of time sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:31:49.565483Z",
     "start_time": "2022-01-22T10:31:48.879790Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sample'] = 'default'\n",
    "\n",
    "# define 'hoot' and 'oot' sample\n",
    "data.loc[data[col_month] <= 201801, 'sample'] = 'hoot'\n",
    "data.loc[data[col_month] >= 201811, 'sample'] = 'oot'\n",
    "\n",
    "# define intime mask\n",
    "intime_mask = (data[col_month] > 201801) & (data[col_month] < 201811)\n",
    "# use train_test_split to split the intime into train and rest (don't forget seed)\n",
    "data_train, data_rest = train_test_split(data[intime_mask], test_size=0.4, random_state = 12)\n",
    "data.loc[data_train.index, 'sample'] = 'train'\n",
    "# use train_test_split to split the rest into valid and test (don't forget seed)\n",
    "data_valid, data_test = train_test_split(data_rest, test_size=0.5, random_state = 12)\n",
    "data.loc[data_valid.index, 'sample'] = 'valid'\n",
    "data.loc[data_test.index, 'sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:31:59.692941Z",
     "start_time": "2022-01-22T10:31:59.677941Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sample'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:32:02.556386Z",
     "start_time": "2022-01-22T10:32:02.549386Z"
    }
   },
   "outputs": [],
   "source": [
    "# define function to plot default rate in time for different samples\n",
    "def default_rate_in_time_per_sample(dt, col_target, col_month, col_sample):\n",
    "    # group by over month and sample\n",
    "    dt_grp = dt.groupby([col_month, col_sample]).agg(\n",
    "        def_rt = (col_target, np.mean)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # pivot sample values to columns\n",
    "    dt_grp_pivot = dt_grp.pivot(index = col_month, columns = col_sample, values = 'def_rt')\n",
    "\n",
    "    # plot default rate in time\n",
    "    lines = plt.plot(range(len(dt_grp_pivot)), dt_grp_pivot, marker = 'o')\n",
    "    plt.xticks(range(len(dt_grp_pivot)), dt_grp_pivot.index, rotation = 90)\n",
    "    # set legend\n",
    "    plt.legend(iter(lines), tuple(dt_grp_pivot.columns), loc='best', bbox_to_anchor=(1.05, 1))\n",
    "    \n",
    "    plt.ylim([0, 0.1])\n",
    "    plt.ylabel('default rate', loc='top')\n",
    "    plt.xlabel('month', loc='right')\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('gray')\n",
    "    ax.spines['bottom'].set_color('gray')\n",
    "    ax.tick_params(axis='y', colors='gray')\n",
    "    ax.tick_params(axis='x', colors='gray') \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:32:10.099911Z",
     "start_time": "2022-01-22T10:32:09.855913Z"
    }
   },
   "outputs": [],
   "source": [
    "default_rate_in_time_per_sample(data, col_target, col_month, 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Stratification\n",
    "- Stratification allows us to ensure that in each sample is approximately the same distribution in specified variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:32:34.134372Z",
     "start_time": "2022-01-22T10:32:33.510502Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sample'] = 'default'\n",
    "\n",
    "# define 'hoot' and 'oot' sample\n",
    "data.loc[data[col_month] <= 201801, 'sample'] = 'hoot'\n",
    "data.loc[data[col_month] >= 201811, 'sample'] = 'oot'\n",
    "\n",
    "# define intime mask\n",
    "intime_mask = (data[col_month] > 201801) & (data[col_month] < 201811)\n",
    "# use train_test_split to split the intime into train and rest (don't forget seed); use stratification\n",
    "data_train, data_rest = train_test_split(data[intime_mask], test_size=0.4, random_state = 12, stratify = (data[intime_mask][[col_month, col_target]]))\n",
    "data.loc[data_train.index, 'sample'] = 'train'\n",
    "# use train_test_split to split the rest into valid and test (don't forget seed); use stratification\n",
    "data_valid, data_test = train_test_split(data_rest, test_size=0.5, random_state = 12, stratify = (data_rest[[col_month, col_target]]))\n",
    "data.loc[data_valid.index, 'sample'] = 'valid'\n",
    "data.loc[data_test.index, 'sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:32:36.370494Z",
     "start_time": "2022-01-22T10:32:36.358494Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sample'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:32:38.575728Z",
     "start_time": "2022-01-22T10:32:38.353016Z"
    }
   },
   "outputs": [],
   "source": [
    "default_rate_in_time_per_sample(data, col_target, col_month, 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define sample masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:32:41.772603Z",
     "start_time": "2022-01-22T10:32:41.726574Z"
    }
   },
   "outputs": [],
   "source": [
    "# define sample masks\n",
    "train_mask = (data['sample'] == 'train')\n",
    "valid_mask = (data['sample'] == 'valid')\n",
    "test_mask = (data['sample'] == 'test')\n",
    "oot_mask = (data['sample'] == 'oot')\n",
    "hoot_mask = (data['sample'] == 'hoot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We never want to evaluate performance on the training sample. We can use use all of the observations for both training and validation - using so-called k-fold cross-validation. We are not using it in this notebook, but it is a useful concept, very often used.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*AAwIlHM8TpAVe4l2FihNUQ.png\" width=500px style=\"float: center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(data)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- We need to get rid of infinities, otherwise many numerical procedures fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:43:32.195268Z",
     "start_time": "2022-01-22T09:43:32.065185Z"
    }
   },
   "outputs": [],
   "source": [
    "# find columns with infinity values\n",
    "cols_with_inf = []\n",
    "for col in cols_num:\n",
    "    if np.any(np.isinf(data[col])):\n",
    "        cols_with_inf.append(col)\n",
    "        print(f'Column {col} includes infinity values.')\n",
    "\n",
    "# find columns with negative infinity values\n",
    "cols_with_neginf = []\n",
    "for col in cols_num:\n",
    "    if np.any(np.isneginf(data[col])):\n",
    "        cols_with_neginf.append(col)\n",
    "        print(f'Column {col} includes negative infinity values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:43:33.705322Z",
     "start_time": "2022-01-22T09:43:33.698297Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace infinity values\n",
    "for col in cols_with_inf:\n",
    "    data[col].replace(np.inf, 9999999, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_columns(columns, df):\n",
    "    for col in columns:\n",
    "        print('-' * 50)\n",
    "        print('{}'.format(col.upper()))\n",
    "        print('-' * 50)\n",
    "        print('')\n",
    "        k = int(df[col].nunique())\n",
    "        \n",
    "        \n",
    "        if k < 2:\n",
    "            print(f'{col} - only constant with value {df[col].unique()}')\n",
    "        elif (k < 15) or (df[col].dtype == 'O'):\n",
    "            info = '{:.2f}% is missing'.format(np.mean(df[col].isna()) * 100)\n",
    "            print(info)\n",
    "            \n",
    "            ax = (df[col].value_counts(dropna=False).iloc[0:15] / df[col].shape[0]).plot.bar()\n",
    "            _ = ax.set_title('\\n' + col.replace('_', ' ').upper() + '\\n')\n",
    "            for p in ax.patches:\n",
    "                width = p.get_width()\n",
    "                height = p.get_height()\n",
    "                x, y = p.get_xy() \n",
    "                _ = ax.annotate('{:.2f}%'.format(height * 100), (x + width/2, y + height + 0.02), ha='center')\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            info = '{:.2f}% above 0'.format(np.mean(np.where(df[col] > 0, 1, 0)) * 100)\n",
    "            print(info)\n",
    "\n",
    "            info = '{:.2f}% is missing'.format(np.mean(df[col].isna()) * 100)\n",
    "            print(info)\n",
    "            \n",
    "            ax = df[col].hist(log=True)\n",
    "            _ = ax.set_title('\\n' + col.replace('_', ' ').upper() + '\\n')\n",
    "            plt.show()\n",
    "\n",
    "            ax = df[col].hist(log=False)\n",
    "            _ = ax.set_title('\\n' + col.replace('_', ' ').upper() + '\\n')\n",
    "            plt.show()\n",
    "\n",
    "                \n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_columns(data.columns, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check suspicious variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[['FIRST_TRANSACTION_TIME_MONTHS', 'LAST_TRANSACTION_TIME_MONTHS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['FIRST_TRANSACTION_TIME_MONTHS']>= data['LAST_TRANSACTION_TIME_MONTHS']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Explore more, find more suspicious variables, try to understand the data! </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:38:22.481532Z",
     "start_time": "2022-01-22T09:38:22.466535Z"
    }
   },
   "outputs": [],
   "source": [
    "# define function that plots share of null values in time for given predictor\n",
    "def share_of_nulls(dt, col_month, predictor):\n",
    "    if dt[predictor].isnull().sum() == 0:\n",
    "        return\n",
    "    dt2 = dt[[col_month, predictor]]\n",
    "    \n",
    "    dt2 = dt2.assign(is_null=dt2[predictor].isnull().astype(int).values)\n",
    "    dt_grp = dt2.groupby(col_month).agg(\n",
    "        share_of_nulls = ('is_null', np.mean)\n",
    "    )\n",
    "    \n",
    "    plt.plot(range(len(dt_grp)), dt_grp['share_of_nulls'], marker = 'o')\n",
    "    plt.xticks(range(len(dt_grp)), dt_grp.index, rotation = 90)\n",
    "    plt.title(predictor)\n",
    "    plt.xlabel('month', loc='right')\n",
    "    plt.ylabel('null share', loc='top')\n",
    "    plt.ylim([0,1])\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('gray')\n",
    "    ax.spines['bottom'].set_color('gray')\n",
    "    ax.tick_params(axis='y', colors='gray')\n",
    "    ax.tick_params(axis='x', colors='gray')    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:38:23.277859Z",
     "start_time": "2022-01-22T09:38:22.800898Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pred in data.columns:\n",
    "    share_of_nulls(data, col_month, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:37:04.285654Z",
     "start_time": "2022-01-22T09:37:04.271621Z"
    }
   },
   "outputs": [],
   "source": [
    "# define function that plots default rate in time\n",
    "def default_rate_across_group(data, col_group, col_target, yright_lim = None):\n",
    "    dt = data.copy()\n",
    "    k = int(dt[col_group].nunique())\n",
    "    \n",
    "    if (k > 10) and dt[col_group].dtype != 'O':\n",
    "        dt[col_group] = pd.qcut(dt[col_group], q=10, duplicates='drop')\n",
    "    \n",
    "    dt_grp = dt.groupby(col_group).agg(\n",
    "        tot_cnt = (col_target, len),\n",
    "        default_rate = (col_target, np.mean)\n",
    "    )\n",
    "    \n",
    "    ax1 = plt.subplot(111)\n",
    "    ax1.bar(range(len(dt_grp)), dt_grp['tot_cnt'])\n",
    "    ax1.set_xticks(range(len(dt_grp)))\n",
    "    ax1.set_xticklabels(dt_grp.index, rotation = 90)\n",
    "    ax1.set_xlabel(col_group)\n",
    "    ax1.set_ylabel('count', loc='top')\n",
    "    ax1.spines['right'].set_color('gray')\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['left'].set_color('gray')\n",
    "    ax1.spines['bottom'].set_color('gray')\n",
    "    ax1.tick_params(axis='y', colors='gray')\n",
    "    ax1.tick_params(axis='x', colors='gray')    \n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(range(len(dt_grp)), dt_grp['default_rate'], marker ='o', color = 'red')\n",
    "    ax2.set_ylabel('default rate', loc='top', color='red')\n",
    "    if yright_lim is not None:\n",
    "        ax2.set_ylim(yright_lim)\n",
    "    ax2.spines['right'].set_color('gray')\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['left'].set_color('gray')\n",
    "    ax2.spines['bottom'].set_color('gray')\n",
    "    ax2.tick_params(axis='y', colors='gray')\n",
    "    ax2.tick_params(axis='x', colors='gray')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:37:05.833934Z",
     "start_time": "2022-01-22T09:37:05.563883Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "default_rate_across_group(data, col_month, col_target, yright_lim = [0, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in cols_cat:\n",
    "    default_rate_across_group(data, col, col_target, yright_lim = [0, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in cols_num:\n",
    "    if col=='TARGET':\n",
    "        continue\n",
    "    default_rate_across_group(data, col, col_target, yright_lim = [0, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** add more variables to the list in the next cell </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_use_variables_as_predictors = [\n",
    "    'TARGET'\n",
    "    , 'MONTH'\n",
    "    , 'TIME'\n",
    "    , 'BASE'\n",
    "    , 'DAY'\n",
    "    , 'sample'\n",
    "    , 'FIRST_TRANSACTION_TIME_MONTHS'\n",
    "    , 'LAST_TRANSACTION_TIME_MONTHS'\n",
    "    , 'CNT_CHILDREN'\n",
    "]\n",
    "\n",
    "cols_pred = cols.copy()\n",
    "for variable in dont_use_variables_as_predictors:\n",
    "    if variable in cols_pred:\n",
    "        cols_pred.remove(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of numerical predictors\n",
    "cols_pred_num = [col for col in cols_pred if data[col].dtype != 'O']\n",
    "# define list of categorical predictors\n",
    "cols_pred_cat = [col for col in cols_pred if data[col].dtype == 'O']\n",
    "\n",
    "print('Numerical predictors:')\n",
    "print('---------------------')\n",
    "print(data[cols_pred_num].dtypes)\n",
    "print()\n",
    "print('Categorical predictors:')\n",
    "print('-----------------------')\n",
    "print(data[cols_pred_cat].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bins\n",
    "- Remember, now we must take into account only training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:44:48.655606Z",
     "start_time": "2022-01-22T09:44:48.645607Z"
    }
   },
   "outputs": [],
   "source": [
    "# define bins for grouping numerical predictors\n",
    "def get_grouping(dt, predictor, n_bins = 7):\n",
    "    return np.unique([round(b, 4) for b in dt[predictor].quantile([i / n_bins for i in range(n_bins+1)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:45:17.010237Z",
     "start_time": "2022-01-22T09:45:11.042413Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor_grouping = {}\n",
    "for col in tqdm(cols_pred_num):\n",
    "    predictor_grouping[col] = get_grouping(data[train_mask], col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(cols_pred_num):\n",
    "    data[col] = pd.cut(data[col], bins=predictor_grouping[col])\n",
    "    \n",
    "    # add 'missing' as a new category\n",
    "    data[col] = data[col].values.add_categories('missing')\n",
    "    \n",
    "    # replace nans with 'missing', so it is easier to handle\n",
    "    data[col].fillna('missing', inplace=True)\n",
    "    \n",
    "for col in tqdm(cols_pred_cat):\n",
    "    data[col].fillna('missing', inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Predictors\n",
    "- Category encoding is defined by:\n",
    "$$ CategoryEncoding = \\frac{f_{categ}\\cdot DR_{category} + \\alpha \\cdot DR}{f_{categ} + \\alpha} $$\n",
    "where $f_{categ}$ is frequency of category to be encoded, $DR_{category}$ default rate in this category and $DR$ is total default rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Write mean_target_encoding function </span>\n",
    "\n",
    "The function computes category encoding, you can just fill in this template to have an easier start:\n",
    "\n",
    "\n",
    "    def mean_target_encoding(dt, predictor, target, alpha = 0.01):\n",
    "        \n",
    "        # compute total count and total default rate\n",
    "        # groupby the category\n",
    "        # compute category encoding\n",
    "        \n",
    "        # in the grouped dataframe, if there are some nan, just replace it with total default rate\n",
    "        dt_grp['categ_encoding'].fillna(total_dr, inplace=True)\n",
    "        \n",
    "        return dt_grp[['categ_encoding']].to_dict()['categ_encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(dt, predictor, target, alpha = 0.01):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dr = np.mean(data[train_mask][col_target])\n",
    "\n",
    "for pred in tqdm(cols_pred.copy()):\n",
    "    k = int(data[pred].nunique())\n",
    "    \n",
    "    if k <= 1:\n",
    "        if pred in cols_pred:\n",
    "            cols_pred.remove(pred)\n",
    "            continue\n",
    "            \n",
    "    new_vals = mean_target_encoding(\n",
    "            dt=data[train_mask], \n",
    "            predictor=pred, \n",
    "            target=col_target\n",
    "        )\n",
    "\n",
    "    dt_grp = data.groupby(pred, dropna=False).agg(\n",
    "            categ_dr = (col_target, np.mean),\n",
    "            categ_cnt = (col_target, len)\n",
    "        )\n",
    "\n",
    "    additional_values = set(data[data[pred].notnull()][pred].unique()) - set(new_vals.keys())\n",
    "    for p in additional_values:\n",
    "        new_vals[p] = total_dr\n",
    "\n",
    "    data['MTE_' + pred] = data[pred].replace(new_vals)\n",
    "\n",
    "    if 'MTE_' + pred not in cols_pred:\n",
    "        cols_pred.append('MTE_' + pred)\n",
    "\n",
    "    if pred in cols_pred:\n",
    "        cols_pred.remove(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check_grouping_stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:54:37.499955Z",
     "start_time": "2022-01-22T09:54:37.468915Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictor_stability(dt, predictor, col_target, col_month):\n",
    "    try:\n",
    "        dt_grp = dt.groupby([col_month, predictor]).agg(\n",
    "            obs_cnt = (col_target, len),\n",
    "            default_rate = (col_target, np.mean)\n",
    "        )\n",
    "        dt_grp.reset_index(inplace = True)\n",
    "\n",
    "        dt_grp_pivot = dt_grp.pivot(index = col_month, columns = predictor, values = 'default_rate')\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize = (12,4))\n",
    "        fig.suptitle(predictor)\n",
    "        for col in dt_grp_pivot.columns:\n",
    "            axs[0].plot(range(len(dt_grp_pivot)), dt_grp_pivot[col], label = f'{col:.4f}')\n",
    "\n",
    "        axs[0].set_xticks(range(len(dt_grp_pivot)))\n",
    "        axs[0].set_xticklabels(dt_grp_pivot.index, rotation = 90)\n",
    "        axs[0].set_xlabel('month', loc='right')\n",
    "        axs[0].set_ylabel('default_rate', loc='top')\n",
    "        axs[0].spines['right'].set_visible(False)\n",
    "        axs[0].spines['top'].set_visible(False)\n",
    "        axs[0].spines['left'].set_color('gray')\n",
    "        axs[0].spines['bottom'].set_color('gray')\n",
    "        axs[0].tick_params(axis='y', colors='gray')\n",
    "        axs[0].tick_params(axis='x', colors='gray') \n",
    "        axs[0].legend(loc = 'best')\n",
    "\n",
    "        dt_grp_pivot = dt_grp.pivot(index = col_month, columns = predictor, values = 'obs_cnt')\n",
    "        dt_grp_pivot['tot_cnt'] = dt_grp_pivot.sum(axis = 1)\n",
    "\n",
    "        for col in dt_grp_pivot.columns:\n",
    "            dt_grp_pivot[col] /= dt_grp_pivot['tot_cnt']\n",
    "        del dt_grp_pivot['tot_cnt']\n",
    "\n",
    "        for col in dt_grp_pivot.columns:\n",
    "            axs[1].plot(range(len(dt_grp_pivot)), dt_grp_pivot[col], label = f'{col:.4f}')\n",
    "\n",
    "        axs[1].set_xticks(range(len(dt_grp_pivot)))\n",
    "        axs[1].set_xticklabels(dt_grp_pivot.index, rotation = 90)\n",
    "        axs[1].set_xlabel('month', loc='right')\n",
    "        axs[1].set_ylabel('frequency', loc='top')\n",
    "        axs[1].spines['right'].set_visible(False)\n",
    "        axs[1].spines['top'].set_visible(False)\n",
    "        axs[1].spines['left'].set_color('gray')\n",
    "        axs[1].spines['bottom'].set_color('gray')\n",
    "        axs[1].tick_params(axis='y', colors='gray')\n",
    "        axs[1].tick_params(axis='x', colors='gray') \n",
    "        axs[1].legend(loc = 'best')\n",
    "\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(f'Predictor {predictor} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:55:01.213711Z",
     "start_time": "2022-01-22T09:54:59.562128Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pred in cols_pred:\n",
    "    predictor_stability(data, pred, col_target, col_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:34:38.224784Z",
     "start_time": "2022-01-22T10:34:33.684604Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit logistig regression with all predictors\n",
    "logreg = LogisticRegression(\n",
    "    penalty = 'none',\n",
    "    max_iter = 5000\n",
    ")\n",
    "\n",
    "logreg.fit(data[train_mask][cols_pred], data[train_mask][col_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:34:40.314960Z",
     "start_time": "2022-01-22T10:34:40.295962Z"
    }
   },
   "outputs": [],
   "source": [
    "# print predictor coefficients (sorted by magnitude)\n",
    "preds_coef = []\n",
    "for pred, coef in zip(cols_pred, logreg.coef_[0]):\n",
    "    preds_coef += [(pred, coef)]\n",
    "    \n",
    "sorted(preds_coef, key = lambda x: abs(x[1]), reverse = True)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:34:47.465808Z",
     "start_time": "2022-01-22T10:34:47.343656Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict probability\n",
    "data = data.assign(prediction = logreg.predict_proba(data[cols_pred])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:34:52.936454Z",
     "start_time": "2022-01-22T10:34:52.765136Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate gini for different samples\n",
    "col_score = 'prediction'\n",
    "\n",
    "gini_hoot  = 2 * roc_auc_score(data[hoot_mask][col_target],  data[hoot_mask] [col_score]) - 1\n",
    "gini_train = 2 * roc_auc_score(data[train_mask][col_target], data[train_mask][col_score]) - 1\n",
    "gini_valid = 2 * roc_auc_score(data[valid_mask][col_target], data[valid_mask][col_score]) - 1\n",
    "gini_test  = 2 * roc_auc_score(data[test_mask][col_target],  data[test_mask] [col_score]) - 1\n",
    "gini_oot   = 2 * roc_auc_score(data[oot_mask][col_target],   data[oot_mask]  [col_score]) - 1\n",
    "\n",
    "print(f'hoot:    {gini_hoot:.4f}')\n",
    "print(f'train:   {gini_train:.4f}')\n",
    "print(f'valid:   {gini_valid:.4f}')\n",
    "print(f'test:    {gini_test:.4f}')\n",
    "print(f'oot:     {gini_oot:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:34:38.224784Z",
     "start_time": "2022-01-22T10:34:33.684604Z"
    }
   },
   "outputs": [],
   "source": [
    "coefs = []\n",
    "consts = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "models = []\n",
    "for c in consts:\n",
    "    # fit logistig regression with all predictors and penalty\n",
    "    logreg = LogisticRegression(\n",
    "        penalty = 'l1'\n",
    "        , C = c\n",
    "        , solver = 'liblinear'\n",
    "        , max_iter = 2000\n",
    "    )\n",
    "\n",
    "    logreg.fit(data[train_mask][cols_pred], data[train_mask][col_target])\n",
    "    models.append(logreg)\n",
    "    coefs.append(logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(consts, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Regularization constant')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso coefficients as a function of regularization constant');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the model you like (or better, the best performing model)\n",
    "logreg = models[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:34:47.465808Z",
     "start_time": "2022-01-22T10:34:47.343656Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict probability\n",
    "data = data.assign(prediction = logreg.predict_proba(data[cols_pred])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:34:52.936454Z",
     "start_time": "2022-01-22T10:34:52.765136Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate gini for different samples\n",
    "col_score = 'prediction'\n",
    "\n",
    "gini_hoot  = 2 * roc_auc_score(data[hoot_mask][col_target],  data[hoot_mask] [col_score]) - 1\n",
    "gini_train = 2 * roc_auc_score(data[train_mask][col_target], data[train_mask][col_score]) - 1\n",
    "gini_valid = 2 * roc_auc_score(data[valid_mask][col_target], data[valid_mask][col_score]) - 1\n",
    "gini_test  = 2 * roc_auc_score(data[test_mask][col_target],  data[test_mask] [col_score]) - 1\n",
    "gini_oot   = 2 * roc_auc_score(data[oot_mask][col_target],   data[oot_mask]  [col_score]) - 1\n",
    "\n",
    "print(f'hoot:    {gini_hoot:.4f}')\n",
    "print(f'train:   {gini_train:.4f}')\n",
    "print(f'valid:   {gini_valid:.4f}')\n",
    "print(f'test:    {gini_test:.4f}')\n",
    "print(f'oot:     {gini_oot:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Try using 'l2' and 'elasticnet' regularization with different setups, investigate the performace, which one would you select?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one of the model's prediction \n",
    "data['prediction_final'] = data['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:58:30.093124Z",
     "start_time": "2022-01-22T09:58:30.037129Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.assign(prediction_score = np.log(data['prediction_final'] / (1 - data['prediction_final'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T09:58:31.103026Z",
     "start_time": "2022-01-22T09:58:30.831067Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, treshold_train = roc_curve(data[train_mask][col_target], data[train_mask]['prediction_score'])\n",
    "fpr_valid, tpr_valid, treshold_valid = roc_curve(data[valid_mask][col_target], data[valid_mask]['prediction_score'])\n",
    "fpr_test, tpr_test, treshold_test    = roc_curve(data[test_mask][col_target], data[test_mask]['prediction_score'])\n",
    "fpr_oot, tpr_oot, treshold_oot       = roc_curve(data[oot_mask][col_target], data[oot_mask]['prediction_score'])\n",
    "fpr_hoot, tpr_hoot, treshold_hoot    = roc_curve(data[hoot_mask][col_target], data[hoot_mask]['prediction_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:14:10.739931Z",
     "start_time": "2022-01-22T10:14:10.539931Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.plot(fpr_train, tpr_train, label = 'train')\n",
    "plt.plot(fpr_valid, tpr_valid, label = 'valid')\n",
    "plt.plot(fpr_test, tpr_test, label = 'test')\n",
    "plt.plot(fpr_oot, tpr_oot, label = 'oot')\n",
    "plt.plot(fpr_hoot, tpr_hoot, label = 'hoot')\n",
    "plt.plot([0, 1], [0, 1], ls = '--', color = 'black')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('gray')\n",
    "ax.spines['top'].set_color('gray')\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.tick_params(axis='x', colors='gray') \n",
    "ax.legend(loc = 'best')\n",
    "\n",
    "plt.xlabel('False positive rate', loc='right')\n",
    "plt.ylabel('True positive rate', loc='top')\n",
    "plt.title('Roceiver operating characteristic curve')\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance per Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:17:43.514501Z",
     "start_time": "2022-01-22T10:17:43.363504Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = data['sample'].unique()\n",
    "gini_sample = []\n",
    "for sample in samples:\n",
    "    mask = data['sample'] == sample\n",
    "    gini = 2 * roc_auc_score(data[mask][col_target], data[mask]['prediction_score']) - 1\n",
    "    gini_sample += [(sample, gini)]\n",
    "    \n",
    "pd.DataFrame(gini_sample, columns = ['sample', 'gini']).set_index('sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini in Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:17:46.192934Z",
     "start_time": "2022-01-22T10:17:45.793905Z"
    }
   },
   "outputs": [],
   "source": [
    "months = sorted(data[col_month].unique())\n",
    "gini_in_time = pd.DataFrame(index = months)\n",
    "for sample in data['sample'].unique():\n",
    "    dt = data[data['sample'] == sample]\n",
    "    months_sample = dt[col_month].unique()\n",
    "    gini_sample_month = []\n",
    "    for m in months_sample:\n",
    "        mask = dt[col_month] == m\n",
    "        gini = 2 * roc_auc_score(dt[mask][col_target], dt[mask]['prediction_score']) - 1\n",
    "        gini_sample_month += [(m, gini)]\n",
    "    gini_sample_month = pd.DataFrame(gini_sample_month, columns = [col_month, sample]).set_index(col_month)\n",
    "    gini_in_time = gini_in_time.join(gini_sample_month, how = 'left')\n",
    "gini_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:18:41.205657Z",
     "start_time": "2022-01-22T10:18:40.959624Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "for sample in samples:\n",
    "    plt.plot(range(len(gini_in_time)), gini_in_time[sample], label = sample, marker = 'o')\n",
    "\n",
    "plt.legend(loc = 'best')\n",
    "plt.xticks(range(len(gini_in_time)), gini_in_time.index, rotation = 45)\n",
    "plt.ylim([0,0.6])\n",
    "plt.ylabel('Gini', loc='top')\n",
    "plt.xlabel('month', loc='right')\n",
    "plt.title('Gini in time')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.tick_params(axis='x', colors='gray') \n",
    "ax.legend(loc = 'best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:27:36.696179Z",
     "start_time": "2022-01-22T10:27:36.680179Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_score_calibration(dt, col_score, col_target, n_bins = 25):\n",
    "    min_score = dt[col_score].min() - 0.1\n",
    "    max_score = dt[col_score].max() + 0.1\n",
    "    \n",
    "    bins = [round(min_score + i * (max_score - min_score) / n_bins, 2) for i in range(n_bins+1)]\n",
    "    dt['score_bin'] = pd.cut(dt[col_score], bins = bins, include_lowest = True)\n",
    "    \n",
    "    dt_grp = dt.groupby('score_bin').agg(\n",
    "        bad_cnt = (col_target, sum),\n",
    "        tot_cnt = (col_target, len),\n",
    "        def_rt = (col_target, np.mean),\n",
    "        avg_score = (col_score, np.mean)\n",
    "    )\n",
    "    dt_grp['good_cnt'] = dt_grp['tot_cnt'] - dt_grp['bad_cnt']\n",
    "    dt_grp['bad_cnt_norm'] = dt_grp['bad_cnt'] / dt_grp['tot_cnt']\n",
    "    dt_grp['good_cnt_norm'] = dt_grp['good_cnt'] / dt_grp['tot_cnt']\n",
    "    dt_grp['expected_pd'] = 1 / (1 + np.exp(-dt_grp['avg_score']))\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2, figsize = (12,4))\n",
    "    fig.suptitle(col_score)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    axs[0].bar(range(len(dt_grp)), dt_grp['bad_cnt'], color = 'salmon', label = 'bads')\n",
    "    axs[0].bar(range(len(dt_grp)), dt_grp['good_cnt'], bottom = dt_grp['bad_cnt'], color = 'lightblue', label = 'goods')\n",
    "    axs[0].set_ylabel('observations count', loc='top')\n",
    "    axs[0].set_xlabel('score', loc='right')\n",
    "    axs[0].set_xticks(range(len(dt_grp)))\n",
    "    axs[0].set_xticklabels(dt_grp.index, rotation = 90)\n",
    "    \n",
    "    axs[0].spines['right'].set_color('gray')\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['left'].set_color('gray')\n",
    "    axs[0].spines['bottom'].set_color('gray')\n",
    "    axs[0].tick_params(axis='y', colors='gray')\n",
    "    axs[0].tick_params(axis='x', colors='gray') \n",
    "    \n",
    "    ax0l = axs[0].twinx()\n",
    "    ax0l.plot(range(len(dt_grp)), dt_grp['def_rt'], marker = 'o', color = 'red')\n",
    "    ax0l.plot(range(len(dt_grp)), dt_grp['expected_pd'], color = 'black', ls = '--')\n",
    "    ax0l.set_ylabel('default rate', color = 'red', loc='top')\n",
    "    \n",
    "    ax0l.spines['right'].set_color('gray')\n",
    "    ax0l.spines['top'].set_visible(False)\n",
    "    ax0l.spines['left'].set_color('gray')\n",
    "    ax0l.spines['bottom'].set_color('gray')\n",
    "    ax0l.tick_params(axis='y', colors='gray')\n",
    "    ax0l.tick_params(axis='x', colors='gray') \n",
    "    \n",
    "    axs[1].bar(range(len(dt_grp)), dt_grp['bad_cnt_norm'], color = 'salmon', label = 'bads')\n",
    "    axs[1].bar(range(len(dt_grp)), dt_grp['good_cnt_norm'], bottom = dt_grp['bad_cnt_norm'].fillna(0), color = 'lightblue', label = 'goods')\n",
    "    axs[1].set_ylabel('frequency',loc='top')\n",
    "    axs[1].set_xlabel('score', loc='right')\n",
    "    axs[1].set_xticks(range(len(dt_grp)))\n",
    "    axs[1].set_xticklabels(dt_grp.index, rotation = 90)\n",
    "    \n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['left'].set_color('gray')\n",
    "    axs[1].spines['bottom'].set_color('gray')\n",
    "    axs[1].tick_params(axis='y', colors='gray')\n",
    "    axs[1].tick_params(axis='x', colors='gray')\n",
    "    \n",
    "    return dt_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T10:27:38.508167Z",
     "start_time": "2022-01-22T10:27:37.703715Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_grp = plot_score_calibration(data, 'prediction_score', col_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean target encoding function\n",
    "\n",
    "# def mean_target_encoding(dt, predictor, target, alpha = 0.01):\n",
    "#     total_cnt = len(dt)\n",
    "#     total_dr = np.mean(dt[target])\n",
    "#     dt_grp = dt.groupby(predictor, dropna=False).agg(\n",
    "#         categ_dr = (target, np.mean),\n",
    "#         categ_cnt = (target, len)\n",
    "#     )\n",
    "    \n",
    "#     dt_grp['categ_freq'] = dt_grp['categ_cnt'] / total_cnt\n",
    "#     dt_grp['categ_encoding'] = (dt_grp['categ_freq'] * dt_grp['categ_dr'] + alpha * total_dr) / (dt_grp['categ_freq'] + alpha)\n",
    "    \n",
    "#     dt_grp['categ_encoding'].fillna(total_dr, inplace=True)\n",
    "    \n",
    "#     return dt_grp[['categ_encoding']].to_dict()['categ_encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "342.617px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "638px",
    "left": "1569px",
    "right": "20px",
    "top": "72px",
    "width": "289px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
